{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712bd79d",
   "metadata": {},
   "source": [
    "# NLP Modeling\n",
    "\n",
    "How do we quantify a document?\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Data Representation](#data-representation)\n",
    "    - [Bag of Words](#bag-of-words)\n",
    "    - [TF-IDF](#tf-idf)\n",
    "    - [Bag Of Ngrams](#bag-of-ngrams)\n",
    "- [Modeling](#modeling)\n",
    "    - [Modeling Results](#modeling-results)\n",
    "- [Next Steps](#next-steps)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77207323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def clean(text: str) -> list:\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    text = (text.encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split() # tokenization\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d09b64",
   "metadata": {},
   "source": [
    "## Data Representation\n",
    "\n",
    "Simple data for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b4c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    'Python is pretty cool',\n",
    "    'Python is a nice programming language with nice syntax',\n",
    "    'I think SQL is cool too',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fdb030",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778facc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "bag_of_words = cv.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2721c0-901a-4639-8081-c7a76ff48bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f97319",
   "metadata": {},
   "source": [
    "Here `bag_of_words` is a **sparse matrix**. Usually you should keep it as such,\n",
    "but for demonstration we'll view the data within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef31e3a-5eeb-4394-89ad-8a190f2cd6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cool',\n",
       " 'is',\n",
       " 'language',\n",
       " 'nice',\n",
       " 'pretty',\n",
       " 'programming',\n",
       " 'python',\n",
       " 'sql',\n",
       " 'syntax',\n",
       " 'think',\n",
       " 'too',\n",
       " 'with']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ccdb7a-45f6-49e4-82b2-55d880b9b7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python': 6,\n",
       " 'is': 1,\n",
       " 'pretty': 4,\n",
       " 'cool': 0,\n",
       " 'nice': 3,\n",
       " 'programming': 5,\n",
       " 'language': 2,\n",
       " 'with': 11,\n",
       " 'syntax': 8,\n",
       " 'think': 9,\n",
       " 'sql': 7,\n",
       " 'too': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "290cc53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is pretty cool',\n",
      " 'Python is a nice programming language with nice syntax',\n",
      " 'I think SQL is cool too']\n"
     ]
    }
   ],
   "source": [
    "pprint(data)\n",
    "# Taking a look at the bag of words transformation for education and diagnostics.\n",
    "# In practice this is not necesssary and the resulting data might be to big to be reasonably helpful.\n",
    "bow = pd.DataFrame(bag_of_words.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8425d9-61a0-4e2f-9b60-03668ae00266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>nice</th>\n",
       "      <th>pretty</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "      <th>sql</th>\n",
       "      <th>syntax</th>\n",
       "      <th>think</th>\n",
       "      <th>too</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cool  is  language  nice  pretty  programming  python  sql  syntax  think  \\\n",
       "0     1   1         0     0       1            0       1    0       0      0   \n",
       "1     0   1         1     2       0            1       1    0       1      0   \n",
       "2     1   1         0     0       0            0       0    1       0      1   \n",
       "\n",
       "   too  with  \n",
       "0    0     0  \n",
       "1    0     1  \n",
       "2    1     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd18b2f9-5491-48fb-a9d0-068632bcff9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>nice</th>\n",
       "      <th>pretty</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "      <th>sql</th>\n",
       "      <th>syntax</th>\n",
       "      <th>think</th>\n",
       "      <th>too</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cool     is  language  nice  pretty  programming  python  sql  syntax  \\\n",
       "0  0.25  0.250     0.000  0.00    0.25        0.000   0.250  0.0   0.000   \n",
       "1  0.00  0.125     0.125  0.25    0.00        0.125   0.125  0.0   0.125   \n",
       "2  0.20  0.200     0.000  0.00    0.00        0.000   0.000  0.2   0.000   \n",
       "\n",
       "   think  too   with  \n",
       "0    0.0  0.0  0.000  \n",
       "1    0.0  0.0  0.125  \n",
       "2    0.2  0.2  0.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.apply(lambda row: row / row.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929f4ac",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "- term frequency - inverse document frequency\n",
    "- $\\text{tf} \\times \\text{idf} = \\frac{\\text{tf}}{\\text{df}}$\n",
    "- a measure that helps identify how important a word is in a document\n",
    "- combination of how often a word appears in a document (**tf**) and how unqiue the word\n",
    "  is among documents (**idf**)\n",
    "- used by search engines\n",
    "- naturally helps filter out stopwords\n",
    "- tf is for a single document, idf is for a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c634645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is pretty cool',\n",
      " 'Python is a nice programming language with nice syntax',\n",
      " 'I think SQL is cool too']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>nice</th>\n",
       "      <th>pretty</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "      <th>sql</th>\n",
       "      <th>syntax</th>\n",
       "      <th>think</th>\n",
       "      <th>too</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.373119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197673</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>0.669378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>0.254540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.383770</td>\n",
       "      <td>0.298032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cool        is  language      nice    pretty  programming    python  \\\n",
       "0  0.480458  0.373119  0.000000  0.000000  0.631745     0.000000  0.480458   \n",
       "1  0.000000  0.197673  0.334689  0.669378  0.000000     0.334689  0.254540   \n",
       "2  0.383770  0.298032  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "\n",
       "        sql    syntax     think       too      with  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.334689  0.000000  0.000000  0.334689  \n",
       "2  0.504611  0.000000  0.504611  0.504611  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bag_of_words = tfidf.fit_transform(data)\n",
    "\n",
    "pprint(data)\n",
    "pd.DataFrame(bag_of_words.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879a6e4",
   "metadata": {},
   "source": [
    "To get the idf score for each word (these aren't terribly usefule themselves):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e73321fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is             1.000000\n",
       "cool           1.287682\n",
       "python         1.287682\n",
       "language       1.693147\n",
       "nice           1.693147\n",
       "pretty         1.693147\n",
       "programming    1.693147\n",
       "sql            1.693147\n",
       "syntax         1.693147\n",
       "think          1.693147\n",
       "too            1.693147\n",
       "with           1.693147\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(tfidf.get_feature_names(), tfidf.idf_))).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ba50b",
   "metadata": {},
   "source": [
    "### Bag Of Ngrams\n",
    "\n",
    "For either `CountVectorizer` or `TfidfVectorizer`, you can set the `ngram_range`\n",
    "parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f90e430d-9eb0-4293-9e85-f523c127e768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is pretty cool',\n",
      " 'Python is a nice programming language with nice syntax',\n",
      " 'I think SQL is cool too']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool too</th>\n",
       "      <th>is cool</th>\n",
       "      <th>is nice</th>\n",
       "      <th>is pretty</th>\n",
       "      <th>language with</th>\n",
       "      <th>nice programming</th>\n",
       "      <th>nice syntax</th>\n",
       "      <th>pretty cool</th>\n",
       "      <th>programming language</th>\n",
       "      <th>python is</th>\n",
       "      <th>sql is</th>\n",
       "      <th>think sql</th>\n",
       "      <th>with nice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cool too  is cool  is nice  is pretty  language with  nice programming  \\\n",
       "0         0        0        0          1              0                 0   \n",
       "1         0        0        1          0              1                 1   \n",
       "2         1        1        0          0              0                 0   \n",
       "\n",
       "   nice syntax  pretty cool  programming language  python is  sql is  \\\n",
       "0            0            1                     0          1       0   \n",
       "1            1            0                     1          1       0   \n",
       "2            0            0                     0          0       1   \n",
       "\n",
       "   think sql  with nice  \n",
       "0          0          0  \n",
       "1          0          1  \n",
       "2          1          0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2))\n",
    "bag_of_words = cv.fit_transform(data)\n",
    "\n",
    "pprint(data)\n",
    "pd.DataFrame(bag_of_words.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12896c9b",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d5172aa-73a8-459a-a3bd-68309de6a148",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spam_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/08/8cpsy8b90ddg4tfjy9502gzw0000gn/T/ipykernel_32247/125759022.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spam_clean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spam_clean.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = pd.read_csv('spam_clean.csv')\n",
    "df['clean_text'] = df.text.apply(clean).apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823ff13-cdda-4faa-a516-6e9d9fcf1a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67213d4-839f-454f-acb4-83fc6f1ca2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.clean_text\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7243917-b1a4-49c2-a87b-889e2e704a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_bow = cv.fit_transform(X_train)\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "tree.fit(X_bow, y_train)\n",
    "\n",
    "tree.score(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32deec1e-9786-4349-b0d5-f87f6e066133",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(X_train)\n",
    "tree.fit(X_tfidf, y_train)\n",
    "tree.score(X_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5725ba1-404a-4e83-a419-6ca83f929092",
   "metadata": {},
   "source": [
    "Iterate:\n",
    "\n",
    "- try out the bag of ngrams\n",
    "- try out different ways of text prep (stem vs lemmatize)\n",
    "- etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever transformations we apply to X_train need to be applied to X_test\n",
    "tree.score(tfidf.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780da33c",
   "metadata": {},
   "source": [
    "### Modeling Results\n",
    "\n",
    "A super-useful feature of decision trees and linear models is that they do some\n",
    "built-in feature selection through the coefficeints or feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da113a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(dict(zip(cv.get_feature_names_out(), tree.feature_importances_))).sort_values().tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e11613",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Try other model types\n",
    "\n",
    "    [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "    ([`sklearn`\n",
    "    docs](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html))\n",
    "    is a very popular classifier for NLP tasks.\n",
    "\n",
    "- Look at other metrics, is accuracy the best choice here?\n",
    "\n",
    "- Try ngrams instead of single words\n",
    "\n",
    "- Try a combination of ngrams and words (`ngram_range=(1, 2)` for words and\n",
    "  bigrams)\n",
    "\n",
    "- Try using tf-idf instead of bag of words\n",
    "\n",
    "- Combine the top `n` performing words with the other features that you have\n",
    "  engineered (the `CountVectorizer` and `TfidfVectorizer` have a `vocabulary`\n",
    "  argument you can use to restrict the words used)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
