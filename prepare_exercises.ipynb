{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35aa4f1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03c362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# Speciality\n",
    "import unicodedata\n",
    "import json\n",
    "from time import strftime\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Custom\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53811312",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "**Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:**\n",
    "\n",
    "   - Lowercase everything\n",
    "   - Normalize unicode characters\n",
    "   - Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae02f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one evening as the sun went down\\nand the jungle fire was burning\\ndown the track came a hobo hiking\\nand he said, \"boys, i\\'m not turning\"\\n\"i\\'m headed for a land that\\'s far away\\nbesides the crystal fountains\\nso come with me, we\\'ll go and see\\nthe big rock candy mountains\"\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample String\n",
    "og_string = '''One evening as the sun went down\n",
    "And the jungle fire was burning\n",
    "Down the track came a hobo hiking\n",
    "And he said, \"Boys, I'm not turning\"\n",
    "\"I'm headed for a land that's far away\n",
    "Besides the crystal fountains\n",
    "So come with me, we'll go and see\n",
    "The Big Rock Candy Mountains\"\n",
    "'''\n",
    "og_string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17945f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One evening as the sun went down\\nAnd the jungle fire was burning\\nDown the track came a hobo hiking\\nAnd he said, \"Boys, I\\'m not turning\"\\n\"I\\'m headed for a land that\\'s far away\\nBesides the crystal fountains\\nSo come with me, we\\'ll go and see\\nThe Big Rock Candy Mountains\"\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicodedata.normalize\n",
    "string = unicodedata.normalize('NFKD', og_string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de35961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one evening as the sun went down\\nand the jungle fire was burning\\ndown the track came a hobo hiking\\nand he said boys im not turning\\nim headed for a land thats far away\\nbesides the crystal fountains\\nso come with me well go and see\\nthe big rock candy mountains\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace anything that is not a letter, number, whitespace or a single quote\n",
    "re.sub(r'[^\\w\\s]', '', string).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03ee634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the function\n",
    "def basic_clean(string):\n",
    "    '''\n",
    "    Takes in any string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKD', og_string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r'[^\\w\\s]', '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587d4d7",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "**Define a function named tokenize. It should take in a string and tokenize all the words in the string.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e844a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One evening as the sun went down\n",
      "And the jungle fire was burning\n",
      "Down the track came a hobo hiking\n",
      "And he said , \" Boys , I ' m not turning \" \n",
      " \" I ' m headed for a land that ' s far away\n",
      "Besides the crystal fountains\n",
      "So come with me , we ' ll go and see\n",
      "The Big Rock Candy Mountains \"\n"
     ]
    }
   ],
   "source": [
    "# Make the tokenizer\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "# Use it\n",
    "print(tokenizer.tokenize(og_string, return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d2b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the function\n",
    "def tokenize(string):\n",
    "    '''\n",
    "    Takes in a string and\n",
    "    returns a tokenized string\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55609459",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "**Define a function named stem. It should accept some text and return the text after applying stemming to all the words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c116a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7ccf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65767086",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "**Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73ae18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the lemmatizer\n",
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a12af6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the lemmatizer on each word in the list of words we created by using split\n",
    "lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "# Join our list of words into a string again and assign to a variable\n",
    "string = ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adefa243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it together\n",
    "\n",
    "\n",
    "def lemmatize(string):\n",
    "    '''\n",
    "    Takes in string and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906b2c0c",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "**Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.**\n",
    "\n",
    "**This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db9baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "\n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b20d03",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "**Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58322017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/braedenwright/codeup-data-science/natural-language-processing-exercises/acquire.py:64: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 64 of the file /Users/braedenwright/codeup-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n"
     ]
    }
   ],
   "source": [
    "news_df = acquire.get_inshorts_articles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf0da6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple delays plan requiring employees to come ...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>Apple has delayed its plan that required its e...</td>\n",
       "      <td>18 May 2022,Wednesday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wheat shouldn't go the way of COVID-19 vaccine...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>Calling out the West, India said that wheat sh...</td>\n",
       "      <td>19 May 2022,Thursday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Price of domestic LPG cylinder crosses ₹1,000-...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>The price of a 14.2-kg domestic LPG cylinder w...</td>\n",
       "      <td>19 May 2022,Thursday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rupee closes at a new all-time low of 77.58 ag...</td>\n",
       "      <td>Anmol Sharma</td>\n",
       "      <td>The Indian rupee closed at a new all-time low ...</td>\n",
       "      <td>18 May 2022,Wednesday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Target's shares crash 26%, on track for their ...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>The shares of American department store chain ...</td>\n",
       "      <td>18 May 2022,Wednesday</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          author  \\\n",
       "0  Apple delays plan requiring employees to come ...  Pragya Swastik   \n",
       "1  Wheat shouldn't go the way of COVID-19 vaccine...    Apaar Sharma   \n",
       "2  Price of domestic LPG cylinder crosses ₹1,000-...    Apaar Sharma   \n",
       "3  Rupee closes at a new all-time low of 77.58 ag...    Anmol Sharma   \n",
       "4  Target's shares crash 26%, on track for their ...  Pragya Swastik   \n",
       "\n",
       "                                             content                   date  \\\n",
       "0  Apple has delayed its plan that required its e...  18 May 2022,Wednesday   \n",
       "1  Calling out the West, India said that wheat sh...   19 May 2022,Thursday   \n",
       "2  The price of a 14.2-kg domestic LPG cylinder w...   19 May 2022,Thursday   \n",
       "3  The Indian rupee closed at a new all-time low ...  18 May 2022,Wednesday   \n",
       "4  The shares of American department store chain ...  18 May 2022,Wednesday   \n",
       "\n",
       "   category  \n",
       "0  business  \n",
       "1  business  \n",
       "2  business  \n",
       "3  business  \n",
       "4  business  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce528bba",
   "metadata": {},
   "source": [
    "# Exercise 7\n",
    "**Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "581e1d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/braedenwright/codeup-data-science/natural-language-processing-exercises/acquire.py:18: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 18 of the file /Users/braedenwright/codeup-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n",
      "/Users/braedenwright/codeup-data-science/natural-language-processing-exercises/acquire.py:26: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 26 of the file /Users/braedenwright/codeup-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n"
     ]
    }
   ],
   "source": [
    "codeup_df = acquire.get_blog_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcdc2c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Quest Info Session: IT Jumpstart on Ma...</td>\n",
       "      <td>May 11, 2022</td>\n",
       "      <td>Join our grant partner Project Quest as they d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From Bootcamp to Bootcamp | A Military Appreci...</td>\n",
       "      <td>Apr 27, 2022</td>\n",
       "      <td>In honor of Military Appreciation Month, join ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our Acquisition of the Rackspace Cloud Academy...</td>\n",
       "      <td>Apr 14, 2022</td>\n",
       "      <td>Just about a year ago on April 16th, 2021 we a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learn to Code: HTML &amp; CSS on 4/30</td>\n",
       "      <td>Apr 1, 2022</td>\n",
       "      <td>HTML &amp; CSS are the design building blocks of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learn to Code: Python Workshop on 4/23</td>\n",
       "      <td>Mar 31, 2022</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     published  \\\n",
       "0  Project Quest Info Session: IT Jumpstart on Ma...  May 11, 2022   \n",
       "1  From Bootcamp to Bootcamp | A Military Appreci...  Apr 27, 2022   \n",
       "2  Our Acquisition of the Rackspace Cloud Academy...  Apr 14, 2022   \n",
       "3                  Learn to Code: HTML & CSS on 4/30   Apr 1, 2022   \n",
       "4             Learn to Code: Python Workshop on 4/23  Mar 31, 2022   \n",
       "\n",
       "                                             content  \n",
       "0  Join our grant partner Project Quest as they d...  \n",
       "1  In honor of Military Appreciation Month, join ...  \n",
       "2  Just about a year ago on April 16th, 2021 we a...  \n",
       "3  HTML & CSS are the design building blocks of a...  \n",
       "4  According to LinkedIn, the “#1 Most Promising ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368846b3",
   "metadata": {},
   "source": [
    "# Exercise 8\n",
    "**For each dataframe, produce the following columns:**\n",
    "\n",
    "   - title to hold the title\n",
    "   - original to hold the original article/post content\n",
    "   - clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "   - stemmed to hold the stemmed version of the cleaned data.\n",
    "   - lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0890505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up original column\n",
    "news_df.rename(columns={'content': 'original'}, inplace=True)\n",
    "codeup_df.rename(columns={'content': 'original'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a12fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the articles\n",
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords,\n",
    "                                  extra_words=extra_words,\n",
    "                                  exclude_words=exclude_words)\n",
    "    \n",
    "    df['stemmed'] = df['clean'].apply(stem)\n",
    "    \n",
    "    df['lemmatized'] = df['clean'].apply(lemmatize)\n",
    "    \n",
    "    return df[['title', column,'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f828773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple delays plan requiring employees to come ...</td>\n",
       "      <td>Apple has delayed its plan that required its e...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wheat shouldn't go the way of COVID-19 vaccine...</td>\n",
       "      <td>Calling out the West, India said that wheat sh...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Price of domestic LPG cylinder crosses ₹1,000-...</td>\n",
       "      <td>The price of a 14.2-kg domestic LPG cylinder w...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rupee closes at a new all-time low of 77.58 ag...</td>\n",
       "      <td>The Indian rupee closed at a new all-time low ...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Target's shares crash 26%, on track for their ...</td>\n",
       "      <td>The shares of American department store chain ...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Apple delays plan requiring employees to come ...   \n",
       "1  Wheat shouldn't go the way of COVID-19 vaccine...   \n",
       "2  Price of domestic LPG cylinder crosses ₹1,000-...   \n",
       "3  Rupee closes at a new all-time low of 77.58 ag...   \n",
       "4  Target's shares crash 26%, on track for their ...   \n",
       "\n",
       "                                            original  \\\n",
       "0  Apple has delayed its plan that required its e...   \n",
       "1  Calling out the West, India said that wheat sh...   \n",
       "2  The price of a 14.2-kg domestic LPG cylinder w...   \n",
       "3  The Indian rupee closed at a new all-time low ...   \n",
       "4  The shares of American department store chain ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  one evening sun went jungle fire burning track...   \n",
       "1  one evening sun went jungle fire burning track...   \n",
       "2  one evening sun went jungle fire burning track...   \n",
       "3  one evening sun went jungle fire burning track...   \n",
       "4  one evening sun went jungle fire burning track...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  one even sun went jungl fire burn track came h...   \n",
       "1  one even sun went jungl fire burn track came h...   \n",
       "2  one even sun went jungl fire burn track came h...   \n",
       "3  one even sun went jungl fire burn track came h...   \n",
       "4  one even sun went jungl fire burn track came h...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  one evening sun went jungle fire burning track...  \n",
       "1  one evening sun went jungle fire burning track...  \n",
       "2  one evening sun went jungle fire burning track...  \n",
       "3  one evening sun went jungle fire burning track...  \n",
       "4  one evening sun went jungle fire burning track...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above for news_df's content column.\n",
    "\n",
    "prep_article_data(news_df, 'original', extra_words = ['ha'], exclude_words = ['no']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1ac4ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Quest Info Session: IT Jumpstart on Ma...</td>\n",
       "      <td>Join our grant partner Project Quest as they d...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From Bootcamp to Bootcamp | A Military Appreci...</td>\n",
       "      <td>In honor of Military Appreciation Month, join ...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our Acquisition of the Rackspace Cloud Academy...</td>\n",
       "      <td>Just about a year ago on April 16th, 2021 we a...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learn to Code: HTML &amp; CSS on 4/30</td>\n",
       "      <td>HTML &amp; CSS are the design building blocks of a...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learn to Code: Python Workshop on 4/23</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "      <td>one even sun went jungl fire burn track came h...</td>\n",
       "      <td>one evening sun went jungle fire burning track...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Project Quest Info Session: IT Jumpstart on Ma...   \n",
       "1  From Bootcamp to Bootcamp | A Military Appreci...   \n",
       "2  Our Acquisition of the Rackspace Cloud Academy...   \n",
       "3                  Learn to Code: HTML & CSS on 4/30   \n",
       "4             Learn to Code: Python Workshop on 4/23   \n",
       "\n",
       "                                            original  \\\n",
       "0  Join our grant partner Project Quest as they d...   \n",
       "1  In honor of Military Appreciation Month, join ...   \n",
       "2  Just about a year ago on April 16th, 2021 we a...   \n",
       "3  HTML & CSS are the design building blocks of a...   \n",
       "4  According to LinkedIn, the “#1 Most Promising ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  one evening sun went jungle fire burning track...   \n",
       "1  one evening sun went jungle fire burning track...   \n",
       "2  one evening sun went jungle fire burning track...   \n",
       "3  one evening sun went jungle fire burning track...   \n",
       "4  one evening sun went jungle fire burning track...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  one even sun went jungl fire burn track came h...   \n",
       "1  one even sun went jungl fire burn track came h...   \n",
       "2  one even sun went jungl fire burn track came h...   \n",
       "3  one even sun went jungl fire burn track came h...   \n",
       "4  one even sun went jungl fire burn track came h...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  one evening sun went jungle fire burning track...  \n",
       "1  one evening sun went jungle fire burning track...  \n",
       "2  one evening sun went jungle fire burning track...  \n",
       "3  one evening sun went jungle fire burning track...  \n",
       "4  one evening sun went jungle fire burning track...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above for codeup_df's content column.\n",
    "\n",
    "prep_article_data(codeup_df, 'original', extra_words = ['ha'], exclude_words = ['no']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358c5e3",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "**Ask yourself:**\n",
    "    \n",
    "   - If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "       - Lemmatized\n",
    "   - If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "       - Lemmatized\n",
    "   - If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?\n",
    "       - Lemmatized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231b7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
